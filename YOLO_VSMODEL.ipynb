{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V6E1"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYi_VoDqnfeE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from collections import Counter"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define paths (adjust these based on your actual dataset location)\n",
        "base_path = \"/content/drive/MyDrive/my_folder\"\n",
        "train_images_path = os.path.join(base_path, \"Visual Pollution Dataset/images/train\")\n",
        "val_images_path = os.path.join(base_path, \"Visual Pollution Dataset/images/val\")\n",
        "train_labels_path = os.path.join(base_path, \"Visual Pollution Dataset/labels/train\")\n",
        "val_labels_path = os.path.join(base_path, \"Visual Pollution Dataset/labels/val\")\n",
        "\n",
        "# Class names from dataset.yaml\n",
        "class_names = ['barriers', 'sidewalks', 'pothole']\n",
        "num_classes = len(class_names)\n",
        "\n",
        "# Function to load labels from a .txt file (YOLO format: class_id center_x center_y width height)\n",
        "def load_label(label_path):\n",
        "    with open(label_path, 'r') as f:\n",
        "        lines = f.readlines()\n",
        "    # Take the first object in the label file (for simplicity, assuming one object per image)\n",
        "    if lines:\n",
        "        label_data = lines[0].strip().split()\n",
        "        class_id = int(label_data[0])\n",
        "        bbox = [float(x) for x in label_data[1:]]  # [center_x, center_y, width, height]\n",
        "        return class_id, bbox\n",
        "    return None, None\n",
        "\n",
        "# Function to load images and labels\n",
        "def load_data(images_path, labels_path):\n",
        "    images = []\n",
        "    class_labels = []\n",
        "    bboxes = []\n",
        "    for img_name in os.listdir(images_path):\n",
        "        if not img_name.endswith(('.jpg', '.jpeg', '.png')):\n",
        "            continue\n",
        "        # Load image\n",
        "        img_path = os.path.join(images_path, img_name)\n",
        "        img = cv2.imread(img_path)\n",
        "        if img is None:\n",
        "            continue\n",
        "        # Load corresponding label\n",
        "        label_name = os.path.splitext(img_name)[0] + '.txt'\n",
        "        label_path = os.path.join(labels_path, label_name)\n",
        "        if not os.path.exists(label_path):\n",
        "            continue\n",
        "        class_id, bbox = load_label(label_path)\n",
        "        if class_id is None or bbox is None:\n",
        "            continue\n",
        "        # Resize image to 128x128 for consistency\n",
        "        img = cv2.resize(img, (128, 128))\n",
        "        images.append(img)\n",
        "        class_labels.append(class_id)\n",
        "        bboxes.append(bbox)\n",
        "    return np.array(images), np.array(class_labels), np.array(bboxes)"
      ],
      "metadata": {
        "id": "U61Z4OQtn-63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and validation data\n",
        "print(\"Loading training data...\")\n",
        "train_images, train_class_labels, train_bboxes = load_data(train_images_path, train_labels_path)\n",
        "print(\"Loading validation data...\")\n",
        "val_images, val_class_labels, val_bboxes = load_data(val_images_path, val_labels_path)\n",
        "\n",
        "# Combine train and val for exploration\n",
        "all_images = np.concatenate([train_images, val_images])\n",
        "all_class_labels = np.concatenate([train_class_labels, val_class_labels])\n",
        "all_bboxes = np.concatenate([train_bboxes, val_bboxes])\n",
        "\n",
        "# Print dataset summary\n",
        "print(f\"Total images: {len(all_images)}\")\n",
        "print(\"Class distribution:\")\n",
        "label_counts = Counter(all_class_labels)\n",
        "for class_id, count in label_counts.items():\n",
        "    print(f\"{class_names[class_id]}: {count}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4Oy_2shoEi8",
        "outputId": "4a59e34b-3913-4178-bcd6-2b1513e2d655"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading training data...\n",
            "Loading validation data...\n",
            "Total images: 31795\n",
            "Class distribution:\n",
            "sidewalks: 5923\n",
            "pothole: 20454\n",
            "barriers: 5418\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Normalize pixel values to [0, 1]\n",
        "all_images = all_images.astype('float32') / 255.0\n",
        "\n",
        "# One-hot encode class labels\n",
        "all_class_labels = to_categorical(all_class_labels, num_classes)\n",
        "\n",
        "# Split into train and test sets (80-20 split)\n",
        "X_train, X_test, y_train_class, y_test_class, y_train_bbox, y_test_bbox = train_test_split(\n",
        "    all_images, all_class_labels, all_bboxes, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Create an ImageDataGenerator for data augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Fit the generator on the training data\n",
        "datagen.fit(X_train)"
      ],
      "metadata": {
        "id": "JyGwxU0IoFZ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, Concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.utils import Sequence\n",
        "import numpy as np\n",
        "\n",
        "# Force TensorFlow to use CPU to avoid GPU-related issues\n",
        "tf.config.set_visible_devices([], 'GPU')\n",
        "print(\"Num GPUs Available (should be 0):\", len(tf.config.list_physical_devices('GPU')))\n",
        "\n",
        "# Debug: Check shapes and data types of input data\n",
        "print(\"X_train shape:\", X_train.shape, \"dtype:\", X_train.dtype)\n",
        "print(\"y_train_class shape:\", y_train_class.shape, \"dtype:\", y_train_class.dtype)\n",
        "print(\"y_train_bbox shape:\", y_train_bbox.shape, \"dtype:\", y_train_bbox.dtype)\n",
        "print(\"X_test shape:\", X_test.shape, \"dtype:\", X_test.dtype)\n",
        "print(\"y_test_class shape:\", y_test_class.shape, \"dtype:\", y_test_class.dtype)\n",
        "print(\"y_test_bbox shape:\", y_test_bbox.shape, \"dtype:\", y_test_bbox.dtype)\n",
        "\n",
        "# Ensure data types are float32\n",
        "X_train = X_train.astype('float32')\n",
        "y_train_class = y_train_class.astype('float32')\n",
        "y_train_bbox = y_train_bbox.astype('float32')\n",
        "X_test = X_test.astype('float32')\n",
        "y_test_class = y_test_class.astype('float32')\n",
        "y_test_bbox = y_test_bbox.astype('float32')\n",
        "\n",
        "# Custom data generator for multi-output model with augmentation\n",
        "class MultiOutputDataGenerator(Sequence):\n",
        "    def __init__(self, x, y_class, y_bbox, batch_size, datagen, shuffle=True):\n",
        "        self.x = x\n",
        "        self.y_class = y_class\n",
        "        self.y_bbox = y_bbox\n",
        "        self.batch_size = batch_size\n",
        "        self.datagen = datagen\n",
        "        self.shuffle = shuffle\n",
        "        self.indices = np.arange(len(self.x))\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.x) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        # Get batch indices\n",
        "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "\n",
        "        # Generate batch\n",
        "        batch_x = self.x[batch_indices]\n",
        "        batch_y_class = self.y_class[batch_indices]\n",
        "        batch_y_bbox = self.y_bbox[batch_indices]\n",
        "\n",
        "        # Apply data augmentation\n",
        "        batch_x_aug = np.zeros_like(batch_x)\n",
        "        for i in range(len(batch_x)):\n",
        "            batch_x_aug[i] = self.datagen.random_transform(batch_x[i])\n",
        "            # Ensure pixel values remain in [0, 1]\n",
        "            batch_x_aug[i] = np.clip(batch_x_aug[i], 0, 1)\n",
        "\n",
        "        return batch_x_aug, {'class_output': batch_y_class, 'bbox_output': batch_y_bbox}\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indices)\n",
        "\n",
        "# Define focal loss for class imbalance\n",
        "def focal_loss(gamma=2.0, alpha=0.25):\n",
        "    def focal_loss_fixed(y_true, y_pred):\n",
        "        # Clip predictions to avoid log(0)\n",
        "        epsilon = tf.keras.backend.epsilon()\n",
        "        y_pred = tf.clip_by_value(y_pred, epsilon, 1.0 - epsilon)\n",
        "\n",
        "        # Compute cross-entropy loss\n",
        "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
        "\n",
        "        # Compute focal factors\n",
        "        focal_weight = alpha * tf.math.pow(1 - y_pred, gamma) * y_true\n",
        "        focal_loss = focal_weight * cross_entropy\n",
        "\n",
        "        return tf.reduce_mean(focal_loss)\n",
        "    return focal_loss_fixed\n",
        "\n",
        "# Build a simplified YOLO-like model\n",
        "def build_yolo_model(input_shape=(128, 128, 3), num_classes=3):\n",
        "    inputs = Input(shape=input_shape)\n",
        "\n",
        "    # Backbone: Simple CNN\n",
        "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Flatten()(x)\n",
        "\n",
        "    # Head 1: Class prediction\n",
        "    class_output = Dense(128, activation='relu')(x)\n",
        "    class_output = Dense(num_classes, activation='softmax', name='class_output')(class_output)\n",
        "\n",
        "    # Head 2: Bounding box prediction\n",
        "    bbox_output = Dense(128, activation='relu')(x)\n",
        "    bbox_output = Dense(4, activation='sigmoid', name='bbox_output')(bbox_output)  # [center_x, center_y, width, height]\n",
        "\n",
        "    # Combine outputs\n",
        "    model = Model(inputs, [class_output, bbox_output])\n",
        "    return model\n",
        "\n",
        "# Create data generator for augmentation\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=10,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    zoom_range=0.1,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "# Build and compile the model with focal loss for classification\n",
        "model = build_yolo_model(input_shape=(128, 128, 3), num_classes=num_classes)\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=0.0001),\n",
        "    loss={\n",
        "        'class_output': focal_loss(gamma=2.0, alpha=0.25),\n",
        "        'bbox_output': 'mean_squared_error'\n",
        "    },\n",
        "    loss_weights={\n",
        "        'class_output': 1.0,\n",
        "        'bbox_output': 1.0\n",
        "    },\n",
        "    metrics={\n",
        "        'class_output': 'accuracy'\n",
        "    }\n",
        ")\n",
        "\n",
        "# Define early stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_class_output_loss',\n",
        "    patience=5,\n",
        "    restore_best_weights=True,\n",
        "    verbose=1,\n",
        "    mode='min'\n",
        ")\n",
        "\n",
        "# Create the custom data generator for training\n",
        "batch_size = 8\n",
        "train_generator = MultiOutputDataGenerator(\n",
        "    X_train,\n",
        "    y_train_class,\n",
        "    y_train_bbox,\n",
        "    batch_size=batch_size,\n",
        "    datagen=datagen,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "# Train the model with the custom generator\n",
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=len(X_train) // batch_size,\n",
        "    epochs=100,\n",
        "    validation_data=(X_test, {'class_output': y_test_class, 'bbox_output': y_test_bbox}),\n",
        "    callbacks=[early_stopping],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Save the model in .h5 format\n",
        "model.save('visual_pollution_yolo_focal.h5')\n",
        "print(\"Model saved as 'visual_pollution_yolo_focal.h5'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqdEPZEQoIS2",
        "outputId": "9efdb69a-8fc5-46d1-804c-8c54784c1fc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available (should be 0): 0\n",
            "X_train shape: (25436, 128, 128, 3) dtype: float32\n",
            "y_train_class shape: (25436, 3) dtype: float32\n",
            "y_train_bbox shape: (25436, 4) dtype: float32\n",
            "X_test shape: (6359, 128, 128, 3) dtype: float32\n",
            "y_test_class shape: (6359, 3) dtype: float32\n",
            "y_test_bbox shape: (6359, 4) dtype: float32\n",
            "Epoch 1/100\n",
            "3179/3179 [==============================] - 80s 25ms/step - loss: 0.0632 - class_output_loss: 0.0303 - bbox_output_loss: 0.0329 - class_output_accuracy: 0.6486 - val_loss: 0.0602 - val_class_output_loss: 0.0285 - val_bbox_output_loss: 0.0317 - val_class_output_accuracy: 0.6691\n",
            "Epoch 2/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0595 - class_output_loss: 0.0285 - bbox_output_loss: 0.0310 - class_output_accuracy: 0.6624 - val_loss: 0.0599 - val_class_output_loss: 0.0290 - val_bbox_output_loss: 0.0309 - val_class_output_accuracy: 0.6639\n",
            "Epoch 3/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0580 - class_output_loss: 0.0278 - bbox_output_loss: 0.0302 - class_output_accuracy: 0.6726 - val_loss: 0.0594 - val_class_output_loss: 0.0282 - val_bbox_output_loss: 0.0313 - val_class_output_accuracy: 0.6805\n",
            "Epoch 4/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0572 - class_output_loss: 0.0274 - bbox_output_loss: 0.0298 - class_output_accuracy: 0.6758 - val_loss: 0.0570 - val_class_output_loss: 0.0270 - val_bbox_output_loss: 0.0300 - val_class_output_accuracy: 0.6855\n",
            "Epoch 5/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0564 - class_output_loss: 0.0269 - bbox_output_loss: 0.0296 - class_output_accuracy: 0.6854 - val_loss: 0.0604 - val_class_output_loss: 0.0309 - val_bbox_output_loss: 0.0295 - val_class_output_accuracy: 0.6710\n",
            "Epoch 6/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0558 - class_output_loss: 0.0265 - bbox_output_loss: 0.0293 - class_output_accuracy: 0.6878 - val_loss: 0.0555 - val_class_output_loss: 0.0261 - val_bbox_output_loss: 0.0294 - val_class_output_accuracy: 0.7028\n",
            "Epoch 7/100\n",
            "3179/3179 [==============================] - 78s 25ms/step - loss: 0.0551 - class_output_loss: 0.0260 - bbox_output_loss: 0.0290 - class_output_accuracy: 0.6940 - val_loss: 0.0549 - val_class_output_loss: 0.0259 - val_bbox_output_loss: 0.0290 - val_class_output_accuracy: 0.7003\n",
            "Epoch 8/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0546 - class_output_loss: 0.0257 - bbox_output_loss: 0.0289 - class_output_accuracy: 0.6926 - val_loss: 0.0557 - val_class_output_loss: 0.0264 - val_bbox_output_loss: 0.0294 - val_class_output_accuracy: 0.7020\n",
            "Epoch 9/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0542 - class_output_loss: 0.0255 - bbox_output_loss: 0.0287 - class_output_accuracy: 0.6977 - val_loss: 0.0550 - val_class_output_loss: 0.0258 - val_bbox_output_loss: 0.0292 - val_class_output_accuracy: 0.7080\n",
            "Epoch 10/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0537 - class_output_loss: 0.0252 - bbox_output_loss: 0.0285 - class_output_accuracy: 0.7035 - val_loss: 0.0591 - val_class_output_loss: 0.0296 - val_bbox_output_loss: 0.0294 - val_class_output_accuracy: 0.6919\n",
            "Epoch 11/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0531 - class_output_loss: 0.0248 - bbox_output_loss: 0.0283 - class_output_accuracy: 0.7046 - val_loss: 0.0543 - val_class_output_loss: 0.0252 - val_bbox_output_loss: 0.0291 - val_class_output_accuracy: 0.7124\n",
            "Epoch 12/100\n",
            "3179/3179 [==============================] - 78s 24ms/step - loss: 0.0528 - class_output_loss: 0.0246 - bbox_output_loss: 0.0282 - class_output_accuracy: 0.7101 - val_loss: 0.0543 - val_class_output_loss: 0.0253 - val_bbox_output_loss: 0.0290 - val_class_output_accuracy: 0.7122\n",
            "Epoch 13/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0524 - class_output_loss: 0.0244 - bbox_output_loss: 0.0280 - class_output_accuracy: 0.7101 - val_loss: 0.0544 - val_class_output_loss: 0.0256 - val_bbox_output_loss: 0.0288 - val_class_output_accuracy: 0.7066\n",
            "Epoch 14/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0520 - class_output_loss: 0.0241 - bbox_output_loss: 0.0279 - class_output_accuracy: 0.7159 - val_loss: 0.0543 - val_class_output_loss: 0.0256 - val_bbox_output_loss: 0.0286 - val_class_output_accuracy: 0.7149\n",
            "Epoch 15/100\n",
            "3179/3179 [==============================] - 78s 25ms/step - loss: 0.0516 - class_output_loss: 0.0238 - bbox_output_loss: 0.0278 - class_output_accuracy: 0.7174 - val_loss: 0.0538 - val_class_output_loss: 0.0251 - val_bbox_output_loss: 0.0287 - val_class_output_accuracy: 0.7135\n",
            "Epoch 16/100\n",
            "3179/3179 [==============================] - 78s 25ms/step - loss: 0.0512 - class_output_loss: 0.0235 - bbox_output_loss: 0.0277 - class_output_accuracy: 0.7207 - val_loss: 0.0547 - val_class_output_loss: 0.0260 - val_bbox_output_loss: 0.0288 - val_class_output_accuracy: 0.7075\n",
            "Epoch 17/100\n",
            "3179/3179 [==============================] - 78s 24ms/step - loss: 0.0509 - class_output_loss: 0.0233 - bbox_output_loss: 0.0276 - class_output_accuracy: 0.7240 - val_loss: 0.0533 - val_class_output_loss: 0.0248 - val_bbox_output_loss: 0.0286 - val_class_output_accuracy: 0.7198\n",
            "Epoch 18/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0505 - class_output_loss: 0.0231 - bbox_output_loss: 0.0274 - class_output_accuracy: 0.7253 - val_loss: 0.0541 - val_class_output_loss: 0.0255 - val_bbox_output_loss: 0.0286 - val_class_output_accuracy: 0.7196\n",
            "Epoch 19/100\n",
            "3179/3179 [==============================] - 78s 25ms/step - loss: 0.0502 - class_output_loss: 0.0228 - bbox_output_loss: 0.0273 - class_output_accuracy: 0.7277 - val_loss: 0.0544 - val_class_output_loss: 0.0256 - val_bbox_output_loss: 0.0289 - val_class_output_accuracy: 0.7158\n",
            "Epoch 20/100\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0495 - class_output_loss: 0.0224 - bbox_output_loss: 0.0271 - class_output_accuracy: 0.7321 - val_loss: 0.0533 - val_class_output_loss: 0.0248 - val_bbox_output_loss: 0.0285 - val_class_output_accuracy: 0.7198\n",
            "Epoch 21/100\n",
            "3179/3179 [==============================] - 78s 25ms/step - loss: 0.0493 - class_output_loss: 0.0223 - bbox_output_loss: 0.0270 - class_output_accuracy: 0.7358 - val_loss: 0.0552 - val_class_output_loss: 0.0259 - val_bbox_output_loss: 0.0293 - val_class_output_accuracy: 0.7184\n",
            "Epoch 22/100\n",
            "3177/3179 [============================>.] - ETA: 0s - loss: 0.0490 - class_output_loss: 0.0220 - bbox_output_loss: 0.0270 - class_output_accuracy: 0.7376Restoring model weights from the end of the best epoch: 17.\n",
            "3179/3179 [==============================] - 79s 25ms/step - loss: 0.0490 - class_output_loss: 0.0220 - bbox_output_loss: 0.0270 - class_output_accuracy: 0.7377 - val_loss: 0.0532 - val_class_output_loss: 0.0249 - val_bbox_output_loss: 0.0283 - val_class_output_accuracy: 0.7257\n",
            "Epoch 22: early stopping\n",
            "Model saved as 'visual_pollution_yolo_focal.h5'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "# Function to compute IoU (Intersection over Union) for bounding boxes\n",
        "def compute_iou(box1, box2):\n",
        "    # box1 and box2 are in [center_x, center_y, width, height] format\n",
        "    # Convert to [x1, y1, x2, y2] format\n",
        "    x1_1 = box1[0] - box1[2] / 2\n",
        "    y1_1 = box1[1] - box1[3] / 2\n",
        "    x2_1 = box1[0] + box1[2] / 2\n",
        "    y2_1 = box1[1] + box1[3] / 2\n",
        "\n",
        "    x1_2 = box2[0] - box2[2] / 2\n",
        "    y1_2 = box2[1] - box2[3] / 2\n",
        "    x2_2 = box2[0] + box2[2] / 2\n",
        "    y2_2 = box2[1] + box2[3] / 2\n",
        "\n",
        "    # Compute intersection coordinates\n",
        "    x1_i = max(x1_1, x1_2)\n",
        "    y1_i = max(y1_1, y1_2)\n",
        "    x2_i = min(x2_1, x2_2)\n",
        "    y2_i = min(y2_1, y2_2)\n",
        "\n",
        "    # Compute intersection area\n",
        "    intersection = max(0, x2_i - x1_i) * max(0, y2_i - y1_i)\n",
        "\n",
        "    # Compute union area\n",
        "    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "    union = area1 + area2 - intersection\n",
        "\n",
        "    return intersection / (union + 1e-6)  # Avoid division by zero\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "all_true_classes = []\n",
        "all_pred_classes = []\n",
        "all_true_bboxes = []\n",
        "all_pred_bboxes = []\n",
        "ious = []\n",
        "maes = []\n",
        "\n",
        "class_output, bbox_output = model.predict(X_test, batch_size=8, verbose=1)\n",
        "\n",
        "# Classification predictions\n",
        "pred_classes = np.argmax(class_output, axis=1)\n",
        "true_classes = np.argmax(y_test_class, axis=1)\n",
        "\n",
        "# Bounding box predictions\n",
        "pred_bboxes = bbox_output\n",
        "true_bboxes = y_test_bbox\n",
        "\n",
        "# Collect predictions and true values\n",
        "all_true_classes.extend(true_classes)\n",
        "all_pred_classes.extend(pred_classes)\n",
        "all_true_bboxes.extend(true_bboxes)\n",
        "all_pred_bboxes.extend(pred_bboxes)\n",
        "\n",
        "# Compute IoU for each sample\n",
        "for t_bbox, p_bbox in zip(true_bboxes, pred_bboxes):\n",
        "    iou = compute_iou(t_bbox, p_bbox)\n",
        "    ious.append(iou)\n",
        "\n",
        "    # Compute MAE for bounding box coordinates\n",
        "    mae = np.mean(np.abs(t_bbox - p_bbox))\n",
        "    maes.append(mae)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "all_true_classes = np.array(all_true_classes)\n",
        "all_pred_classes = np.array(all_pred_classes)\n",
        "all_true_bboxes = np.array(all_true_bboxes)\n",
        "all_pred_bboxes = np.array(all_pred_bboxes)\n",
        "ious = np.array(ious)\n",
        "maes = np.array(maes)\n",
        "\n",
        "# Compute classification metrics\n",
        "accuracy = accuracy_score(all_true_classes, all_pred_classes)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(all_true_classes, all_pred_classes, average=None, labels=[0, 1, 2])\n",
        "class_metrics = {class_names[i]: {'precision': precision[i], 'recall': recall[i], 'f1': f1[i]} for i in range(num_classes)}\n",
        "\n",
        "# Compute average IoU and MAE for bounding boxes\n",
        "mean_iou = np.mean(ious)\n",
        "mean_mae = np.mean(maes)\n",
        "\n",
        "# Print evaluation report\n",
        "print(\"=== Model Evaluation on Test Set ===\")\n",
        "print(f\"Classification Accuracy: {accuracy:.4f}\")\n",
        "print(\"\\nClass-wise Metrics:\")\n",
        "for class_name, metrics in class_metrics.items():\n",
        "    print(f\"{class_name}:\")\n",
        "    print(f\"  Precision: {metrics['precision']:.4f}\")\n",
        "    print(f\"  Recall: {metrics['recall']:.4f}\")\n",
        "    print(f\"  F1-Score: {metrics['f1']:.4f}\")\n",
        "\n",
        "print(f\"\\nBounding Box Metrics:\")\n",
        "print(f\"  Mean IoU: {mean_iou:.4f}\")\n",
        "print(f\"  Mean Absolute Error (MAE): {mean_mae:.4f}\")\n",
        "\n",
        "# Compute IoU distribution for further analysis\n",
        "iou_thresholds = [0.5, 0.75, 0.9]\n",
        "for thresh in iou_thresholds:\n",
        "    iou_above_threshold = np.mean(ious >= thresh)\n",
        "    print(f\"  IoU >= {thresh}: {iou_above_threshold:.4f}\")\n",
        "\n",
        "# Visualize detection results on a few test images\n",
        "num_samples = 5\n",
        "sample_images = X_test[:num_samples]\n",
        "true_class_labels = y_test_class[:num_samples]\n",
        "true_bboxes = y_test_bbox[:num_samples]\n",
        "\n",
        "# Predict class probabilities and bounding boxes\n",
        "pred_class_probs, pred_bboxes = model.predict(sample_images, batch_size=8, verbose=1)\n",
        "\n",
        "plt.figure(figsize=(15, 3))\n",
        "for i in range(num_samples):\n",
        "    img = sample_images[i].copy() * 255.0  # Denormalize for visualization\n",
        "    img = img.astype(np.uint8)\n",
        "\n",
        "    # True bounding box\n",
        "    true_bbox = true_bboxes[i]\n",
        "    true_x = int(true_bbox[0] * 128)  # center_x\n",
        "    true_y = int(true_bbox[1] * 128)  # center_y\n",
        "    true_w = int(true_bbox[2] * 128)  # width\n",
        "    true_h = int(true_bbox[3] * 128)  # height\n",
        "    true_x1 = int(true_x - true_w / 2)\n",
        "    true_y1 = int(true_y - true_h / 2)\n",
        "    true_x2 = int(true_x + true_w / 2)\n",
        "    true_y2 = int(true_y + true_h / 2)\n",
        "    true_class = class_names[np.argmax(true_class_labels[i])]\n",
        "\n",
        "    # Predicted bounding box\n",
        "    pred_bbox = pred_bboxes[i]\n",
        "    pred_x = int(pred_bbox[0] * 128)\n",
        "    pred_y = int(pred_bbox[1] * 128)\n",
        "    pred_w = int(pred_bbox[2] * 128)\n",
        "    pred_h = int(pred_bbox[3] * 128)\n",
        "    pred_x1 = int(pred_x - pred_w / 2)\n",
        "    pred_y1 = int(pred_y - pred_h / 2)\n",
        "    pred_x2 = int(pred_x + pred_w / 2)\n",
        "    pred_y2 = int(pred_y + pred_h / 2)\n",
        "    pred_class = class_names[np.argmax(pred_class_probs[i])]\n",
        "\n",
        "    # Draw true bounding box (green)\n",
        "    cv2.rectangle(img, (true_x1, true_y1), (true_x2, true_y2), (0, 255, 0), 2)\n",
        "    cv2.putText(img, f\"True: {true_class}\", (true_x1, true_y1-10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    # Draw predicted bounding box (red)\n",
        "    cv2.rectangle(img, (pred_x1, pred_y1), (pred_x2, pred_y2), (255, 0, 0), 2)\n",
        "    cv2.putText(img, f\"Pred: {pred_class}\", (pred_x1, pred_y1-30), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 0, 0), 2)\n",
        "\n",
        "    # Plot the image\n",
        "    plt.subplot(1, num_samples, i+1)\n",
        "    plt.imshow(img)\n",
        "    plt.axis('off')\n",
        "\n",
        "plt.savefig('detection_results.png')\n",
        "plt.close()\n",
        "\n",
        "print(\"Detection results saved as 'detection_results.png'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a3P-oYKaoNMG",
        "outputId": "e598719f-90ae-49c1-94ae-7e5807e39cc1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "795/795 [==============================] - 4s 5ms/step\n",
            "=== Model Evaluation on Test Set ===\n",
            "Classification Accuracy: 0.7198\n",
            "\n",
            "Class-wise Metrics:\n",
            "barriers:\n",
            "  Precision: 0.4670\n",
            "  Recall: 0.3791\n",
            "  F1-Score: 0.4185\n",
            "sidewalks:\n",
            "  Precision: 0.5888\n",
            "  Recall: 0.3835\n",
            "  F1-Score: 0.4645\n",
            "pothole:\n",
            "  Precision: 0.7860\n",
            "  Recall: 0.9032\n",
            "  F1-Score: 0.8405\n",
            "\n",
            "Bounding Box Metrics:\n",
            "  Mean IoU: 0.1660\n",
            "  Mean Absolute Error (MAE): 0.1239\n",
            "  IoU >= 0.5: 0.0808\n",
            "  IoU >= 0.75: 0.0060\n",
            "  IoU >= 0.9: 0.0000\n",
            "1/1 [==============================] - 0s 20ms/step\n",
            "Detection results saved as 'detection_results.png'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "# Function to compute IoU (Intersection over Union) for bounding boxes\n",
        "def compute_iou(box1, box2):\n",
        "    # box1 and box2 are in [center_x, center_y, width, height] format\n",
        "    # Convert to [x1, y1, x2, y2] format\n",
        "    x1_1 = box1[0] - box1[2] / 2\n",
        "    y1_1 = box1[1] - box1[3] / 2\n",
        "    x2_1 = box1[0] + box1[2] / 2\n",
        "    y2_1 = box1[1] + box1[3] / 2\n",
        "\n",
        "    x1_2 = box2[0] - box2[2] / 2\n",
        "    y1_2 = box2[1] - box2[3] / 2\n",
        "    x2_2 = box2[0] + box2[2] / 2\n",
        "    y2_2 = box2[1] + box2[3] / 2\n",
        "\n",
        "    # Compute intersection coordinates\n",
        "    x1_i = max(x1_1, x1_2)\n",
        "    y1_i = max(y1_1, y1_2)\n",
        "    x2_i = min(x2_1, x2_2)\n",
        "    y2_i = min(y2_1, y2_2)\n",
        "\n",
        "    # Compute intersection area\n",
        "    intersection = max(0, x2_i - x1_i) * max(0, y2_i - y1_i)\n",
        "\n",
        "    # Compute union area\n",
        "    area1 = (x2_1 - x1_1) * (y2_1 - y1_1)\n",
        "    area2 = (x2_2 - x1_2) * (y2_2 - y1_2)\n",
        "    union = area1 + area2 - intersection\n",
        "\n",
        "    return intersection / (union + 1e-6)  # Avoid division by zero\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "all_true_classes = []\n",
        "all_pred_classes = []\n",
        "all_true_bboxes = []\n",
        "all_pred_bboxes = []\n",
        "ious = []\n",
        "maes = []\n",
        "\n",
        "# Get predictions\n",
        "class_output, bbox_output = model.predict(X_test, batch_size=8, verbose=1)\n",
        "\n",
        "# Classification predictions\n",
        "pred_classes = np.argmax(class_output, axis=1)\n",
        "true_classes = np.argmax(y_test_class, axis=1)\n",
        "\n",
        "# Bounding box predictions\n",
        "pred_bboxes = bbox_output\n",
        "true_bboxes = y_test_bbox\n",
        "\n",
        "# Collect predictions and true values\n",
        "all_true_classes.extend(true_classes)\n",
        "all_pred_classes.extend(pred_classes)\n",
        "all_true_bboxes.extend(true_bboxes)\n",
        "all_pred_bboxes.extend(pred_bboxes)\n",
        "\n",
        "# Compute IoU and MAE for each sample\n",
        "for t_bbox, p_bbox in zip(true_bboxes, pred_bboxes):\n",
        "    iou = compute_iou(t_bbox, p_bbox)\n",
        "    ious.append(iou)\n",
        "    mae = np.mean(np.abs(t_bbox - p_bbox))\n",
        "    maes.append(mae)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "all_true_classes = np.array(all_true_classes)\n",
        "all_pred_classes = np.array(all_pred_classes)\n",
        "all_true_bboxes = np.array(all_true_bboxes)\n",
        "all_pred_bboxes = np.array(all_pred_bboxes)\n",
        "ious = np.array(ious)\n",
        "maes = np.array(maes)\n",
        "\n",
        "# Compute classification metrics\n",
        "accuracy = accuracy_score(all_true_classes, all_pred_classes)\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(all_true_classes, all_pred_classes, average=None, labels=[0, 1, 2])\n",
        "class_metrics = {class_names[i]: {'precision': precision[i], 'recall': recall[i], 'f1': f1[i]} for i in range(num_classes)}\n",
        "\n",
        "# Compute average IoU and MAE for bounding boxes\n",
        "mean_iou = np.mean(ious)\n",
        "mean_mae = np.mean(maes)\n",
        "\n",
        "print(\"Computed predictions and metrics successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWRc9ynwTedG",
        "outputId": "734159a6-18da-41e7-9ba3-c2fa655d8bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "795/795 [==============================] - 4s 5ms/step\n",
            "Computed predictions and metrics successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Compute classification confusion matrix\n",
        "class_cm = confusion_matrix(all_true_classes, all_pred_classes, labels=[0, 1, 2])\n",
        "\n",
        "# Plot classification confusion matrix\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(class_cm, annot=True, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
        "plt.title('Classification Confusion Matrix')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.savefig('classification_confusion_matrix.png')\n",
        "plt.close()\n",
        "\n",
        "print(\"Classification Confusion Matrix:\")\n",
        "print(class_cm)\n",
        "print(\"\\nLabels:\", class_names)\n",
        "print(\"Classification confusion matrix saved as 'classification_confusion_matrix.png'.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IkQKJvp5Tfkb",
        "outputId": "19c3587f-9475-4d26-be16-44b5b96766b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Confusion Matrix:\n",
            "[[ 389  146  491]\n",
            " [ 223  464  523]\n",
            " [ 221  178 3724]]\n",
            "\n",
            "Labels: ['barriers', 'sidewalks', 'pothole']\n",
            "Classification confusion matrix saved as 'classification_confusion_matrix.png'.\n"
          ]
        }
      ]
    }
  ]
}